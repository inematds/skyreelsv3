<p align="center">
  <img src="assets/logo2.png" alt="SkyReels Logo" width="40%">
</p>

<h1 align="center">SkyReels V3 ‚Äî INEMA Web UI</h1>

<p align="center">
  Fork do <a href="https://github.com/SkyworkAI/SkyReels-V3">SkyworkAI/SkyReels-V3</a> com Web UI completa para produ√ß√£o de epis√≥dios em batch.
</p>

---

## O que √© este projeto

Este reposit√≥rio √© um fork do modelo de gera√ß√£o de v√≠deo **SkyReels V3**, com uma interface Web (Web UI) constru√≠da sobre ele para produ√ß√£o de v√≠deos em escala ‚Äî especialmente s√©ries animadas com m√∫ltiplos personagens e cenas.

### Funcionalidades adicionadas neste fork

- **Web UI completa** ‚Äî gera√ß√£o individual ou em fila, sem linha de comando
- **Named Queues** ‚Äî filas nomeadas com dezenas de cenas, controle por cena, retomada ap√≥s erro
- **Suporte a `talking_avatar` na UI** ‚Äî imagem de personagem + √°udio MP3 ‚Üí v√≠deo falante
- **Importa√ß√£o de epis√≥dio via JSON** ‚Äî uma cena por objeto, suporte a tipos mistos
- **Edi√ß√£o de cenas em runtime** ‚Äî altere prompt, seed, resolu√ß√£o sem reiniciar a fila
- **Finaliza√ß√£o autom√°tica** ‚Äî concatena√ß√£o das cenas conclu√≠das em um v√≠deo final via ffmpeg
- **Galeria de v√≠deos** ‚Äî visualiza√ß√£o de todos os v√≠deos gerados com player e privacidade por card

---

## Modelos suportados (SkyReels V3)

| Task | Modelo | HuggingFace |
|---|---|---|
| `reference_to_video` | 14B | [SkyReels-V3-R2V-14B](https://huggingface.co/Skywork/SkyReels-V3-R2V-14B) |
| `single_shot_extension` | 14B | [SkyReels-V3-V2V-14B](https://huggingface.co/Skywork/SkyReels-V3-V2V-14B) |
| `shot_switching_extension` | 14B | [SkyReels-V3-V2V-14B](https://huggingface.co/Skywork/SkyReels-V3-V2V-14B) |
| `talking_avatar` | 19B | [SkyReels-V3-A2V-19B](https://huggingface.co/Skywork/SkyReels-V3-A2V-19B) |

---

## Instala√ß√£o

```bash
git clone https://github.com/inematds/skyreelsv3
cd skyreelsv3

python3.12 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt

# Opcional mas recomendado
pip install flash-attn --no-build-isolation  # aten√ß√£o flash (hardware compat√≠vel)
pip install xfuser                           # multi-GPU
pip install torchao                          # FP8 / Low VRAM mode
```

Os modelos s√£o baixados automaticamente do HuggingFace na primeira execu√ß√£o.

---

## Rodando a Web UI

```bash
source .venv/bin/activate
python webui/app.py
# ‚Üí http://localhost:7860
```

Acesse de qualquer dispositivo na rede local via `http://<ip-do-servidor>:7860`.

---

## Web UI ‚Äî Painel de Gera√ß√£o

### Campos do formul√°rio

| Campo | Descri√ß√£o |
|---|---|
| **Task Type** | `reference_to_video` ¬∑ `single_shot_extension` ¬∑ `shot_switching_extension` ¬∑ `talking_avatar` |
| **Prompt** | Descri√ß√£o textual do v√≠deo desejado |
| **Reference Images** | Caminhos separados por v√≠rgula ‚Äî 1 a 4 imagens (`reference_to_video`) |
| **Input Video** | Caminho local ou URL para tasks de extens√£o |
| **Portrait Image** | Imagem de retrato para `talking_avatar` (jpg / png / gif / bmp) |
| **Audio File** | √Åudio de condu√ß√£o para `talking_avatar` (mp3 / wav ¬∑ m√°x 200 s) |
| **Resolution** | `480P` / `540P` / `720P` ‚Äî `talking_avatar` s√≥ aceita `480P` ou `720P` |
| **Duration** | Segundos de sa√≠da ‚Äî ignorado em `talking_avatar` (definido pelo √°udio) |
| **Seed** | Semente para reprodutibilidade |
| **Offload CPU** | Move modelos para CPU entre passes ‚Äî reduz VRAM |
| **Low VRAM** | Quantiza√ß√£o FP8 + block offload ‚Äî necess√°rio para `talking_avatar` em GPUs < 24 GB |

### Bot√µes de a√ß√£o

- **Gerar V√≠deo** ‚Äî inicia gera√ß√£o imediata
- **+ Fila** ‚Äî adiciona √† fila simples (tab Fila)

---

## Web UI ‚Äî Named Queues (Produ√ß√£o em Batch)

A aba **Fila** suporta filas nomeadas com m√∫ltiplas cenas. Ideal para produ√ß√£o de epis√≥dios com dezenas de takes.

### A√ß√µes por fila

| Bot√£o | A√ß√£o |
|---|---|
| **‚Üë Importar** | Carrega um arquivo `.json` como nova fila nomeada |
| **‚ñ∂ Continuar** | Executa todas as cenas `idle` em sequ√™ncia, pula erros |
| **‚Ü© Repetir do erro** | Reseta cenas com erro e retoma daquele ponto |
| **‚Ü∫ Reiniciar do zero** | Reseta todas (incluindo `done`) e come√ßa do in√≠cio |
| **üé¨ Finalizar** | Concatena todos os v√≠deos `done` em um `.mp4` final via ffmpeg |
| **üóë** | Exclui a fila |

Cada card de cena exibe status, tipo, resolu√ß√£o e seed. Ao abrir a fila as cenas aparecem expandidas. Controles ‚äû (expandir todas) / ‚äü (colapsar todas) dispon√≠veis.

### Edi√ß√£o de cena em runtime

Clique em ‚úèÔ∏è em qualquer cena com status `idle` ou `error` para editar prompt, seed, resolu√ß√£o, arquivos de refer√™ncia e outros campos ‚Äî sem precisar reiniciar o servidor.

### API REST (PATCH)

```bash
# Alterar par√¢metros de uma cena espec√≠fica
curl -X PATCH http://localhost:7860/nqueues/<fila_id>/jobs/<job_id> \
  -H "Content-Type: application/json" \
  -d '{"resolution": "720P", "seed": 9999, "prompt": "novo prompt"}'
```

Campos protegidos (n√£o alter√°veis): `id`, `nq_id`, `status`, `task_type`, `created_at`, `output_video`.

---

## Formato JSON de Epis√≥dio

Importe um arquivo `.json` com um array de cenas para criar uma fila nomeada. Tipos de task podem ser misturados no mesmo arquivo.

```json
[
  {
    "label": "C01-A ¬∑ Corredor ‚Äî Estabelecimento",
    "task_type": "reference_to_video",
    "prompt": "A modern school hallway on the first day of school...",
    "resolution": "540P",
    "duration": 4,
    "seed": 1001,
    "offload": true,
    "low_vram": false,
    "ref_imgs": [
      "uploads/projeto/cena01.png",
      "uploads/projeto/personagem_a.png",
      "uploads/projeto/personagem_b.png"
    ]
  },
  {
    "label": "C01-B ¬∑ Personagem A ‚Äî 'Foi mal!'",
    "task_type": "talking_avatar",
    "prompt": "A teenage girl, composed but slightly embarrassed, speaking a brief apology.",
    "resolution": "480P",
    "seed": 1002,
    "low_vram": true,
    "input_image": "uploads/projeto/personagem_a.png",
    "input_audio": "uploads/projeto/audio/c01_a_linha1.mp3"
  }
]
```

### Campos por tipo de task

| Campo | `reference_to_video` | `talking_avatar` | extens√£o |
|---|---|---|---|
| `label` | recomendado | recomendado | recomendado |
| `task_type` | obrigat√≥rio | obrigat√≥rio | obrigat√≥rio |
| `prompt` | obrigat√≥rio | obrigat√≥rio | obrigat√≥rio |
| `resolution` | `480P`/`540P`/`720P` | **`480P` ou `720P`** | `480P`/`540P`/`720P` |
| `duration` | obrigat√≥rio (segundos) | ‚Äî (definido pelo √°udio) | obrigat√≥rio |
| `seed` | opcional | opcional | opcional |
| `offload` | opcional | opcional | opcional |
| `low_vram` | opcional | **obrigat√≥rio** em < 24 GB | opcional |
| `ref_imgs` | obrigat√≥rio (1‚Äì4 caminhos) | ‚Äî | ‚Äî |
| `input_image` | ‚Äî | obrigat√≥rio | ‚Äî |
| `input_audio` | ‚Äî | obrigat√≥rio | ‚Äî |
| `input_video` | ‚Äî | ‚Äî | obrigat√≥rio |

> ‚ö†Ô∏è **Aten√ß√£o:** caminhos em `ref_imgs` n√£o podem conter v√≠rgulas ‚Äî a CLI usa v√≠rgula como separador.

---

## Organiza√ß√£o de Assets

```
uploads/
‚îî‚îÄ‚îÄ <projeto>/
    ‚îî‚îÄ‚îÄ <episodio>/
        ‚îú‚îÄ‚îÄ cena01.png          # cen√°rios / planos de estabelecimento
        ‚îú‚îÄ‚îÄ cena02.png
        ‚îú‚îÄ‚îÄ personagem_a.png    # retratos de personagens (reutilizados entre cenas)
        ‚îú‚îÄ‚îÄ personagem_b.png
        ‚îî‚îÄ‚îÄ c01_a_linha1.mp3    # √°udios (um por fala)

doc/
‚îî‚îÄ‚îÄ ep01_primeiro_dia.json      # exemplo: 59 cenas (21 r2v + 38 talking_avatar)
```

---

## Modos de Mem√≥ria

| Modo | Flag | VRAM aprox. | Quando usar |
|---|---|---|---|
| Completo | _(nenhuma)_ | ~49 GB (14B) / ~38 GB (19B) | Multi-GPU de alto n√≠vel |
| Offload | `--offload` | ~20 GB (14B) | GPU √∫nica ‚â• 20 GB |
| Low VRAM | `--low_vram` | ~12 GB (14B) / ~19 GB (19B) | GPU √∫nica < 24 GB |

Para Low VRAM, defina tamb√©m:

```bash
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
```

### Notas sobre `talking_avatar` em Low VRAM

- Usar sempre `--low_vram` (quantiza√ß√£o FP8 + block offload)
- Somente `480P` e `720P` s√£o suportados (n√£o `540P`)
- Tempo estimado: ~50 s/step √ó 4 steps √ó N chunks (~3 chunks para 5 s de v√≠deo)

---

## CLI ‚Äî Refer√™ncia r√°pida

```bash
python3 generate_video.py \
  --task_type reference_to_video \
  --ref_imgs "img1.png,img2.png" \
  --prompt "descri√ß√£o do v√≠deo" \
  --resolution 540P \
  --duration 5 \
  --seed 42 \
  --offload
```

```bash
python3 generate_video.py \
  --task_type talking_avatar \
  --input_image personagem.png \
  --input_audio fala.mp3 \
  --resolution 480P \
  --seed 42 \
  --low_vram
```

Sa√≠da salva em `result/<task_type>/<seed>_<timestamp>.mp4`.
Para `talking_avatar`, tamb√©m √© gerado `<seed>_<timestamp>_with_audio.mp4` com o √°udio mixado.

---

## Cr√©ditos

Baseado em [SkyReels V3](https://github.com/SkyworkAI/SkyReels-V3) da [Skywork AI](https://skywork.ai).
Agradecimentos aos projetos: [Wan 2.1](https://github.com/Wan-Video/Wan2.1) ¬∑ [MultiTalk](https://github.com/MeiGen-AI/MultiTalk) ¬∑ [xDiT](https://github.com/xdit-project/xDiT) ¬∑ [diffusers](https://github.com/huggingface/diffusers).
